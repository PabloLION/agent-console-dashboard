# Story: Implement Unix Socket Server

**Story ID:** S001.02 **Epic:**
[E001 - Daemon Core Infrastructure](../epic/E001-daemon-core-infrastructure.md)
**Status:** Draft **Priority:** P1 **Estimated Points:** 5

## Description

As a daemon, I want to listen on a Unix socket for incoming connections, So that
hooks and dashboards can communicate with me via IPC.

## Context

The Unix socket server is the communication layer that enables the client-server
architecture. All clients (hooks from Claude Code sessions and TUI dashboards)
connect to this socket to send commands and receive updates. The socket-based
approach provides:

- Local-only communication (more secure than TCP)
- Low latency (<1ms target)
- No network configuration needed
- Standard filesystem permissions for access control

The socket path defaults to `/tmp/agent-console.sock` but can be customized via
CLI flag or configuration.

The server integrates with the **single-threaded actor model**: all connections
feed into one mpsc channel, and a single event loop processes messages
sequentially. See [concurrency model](../architecture/concurrency.md).

## Implementation Details

### Technical Approach

1. Create `daemon/server.rs` for the socket server implementation
2. Use tokio's `UnixListener` for async socket handling
3. Implement connection accept loop using `tokio::select!` for I/O multiplexing
4. Each connection sends messages to the central mpsc channel (actor's mailbox)
5. Create basic connection handler that reads/writes lines
6. Clean up socket file on graceful shutdown

### Concurrency Architecture

```text
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│ Connection 1│     │ Connection 2│     │ Connection 3│
└──────┬──────┘     └──────┬──────┘     └──────┬──────┘
       │                   │                   │
       └───────────────────┼───────────────────┘
                           │
                           ▼
                   ┌───────────────┐
                   │  mpsc channel │ (bounded queue)
                   └───────┬───────┘
                           │
                           ▼
                   ┌───────────────┐
                   │  Event loop   │ (single-threaded)
                   │  (processes   │
                   │  sequentially)│
                   └───────────────┘
```

All state mutations go through the single message queue. The event loop uses
`tokio::select!` to multiplex I/O (accept connections, read messages, timers)
but processes all state changes sequentially.

### Files to Create/Modify

- `crates/agent-console-dashboard/src/daemon/mod.rs` - Export server module
- `crates/agent-console-dashboard/src/daemon/server.rs` - Unix socket server
  implementation

### Dependencies

- S001.01: Daemon process must exist to host the server

## Acceptance Criteria

- [ ] Given the daemon starts, when the socket path doesn't exist, then a Unix
      socket is created at `/tmp/agent-console.sock`
- [ ] Given a running daemon, when a client connects, then the connection is
      accepted
- [ ] Given multiple clients, when they connect simultaneously, then all
      connections are handled correctly via the mpsc queue
- [ ] Given a connected client, when the client sends text, then the message is
      forwarded to the event loop via mpsc channel
- [ ] Given a connected client, when the server has a response, then the server
      can write back to the client
- [ ] Given the daemon shuts down, when cleanup runs, then the socket file is
      removed
- [ ] Given an existing stale socket file, when daemon starts, then it removes
      the stale file and creates a new socket

## Testing Requirements

- [ ] Unit test: Socket creation at specified path
- [ ] Integration test: Client can connect and exchange messages with server
- [ ] Integration test: Multiple concurrent clients work correctly
- [ ] Integration test: Stale socket file is cleaned up on startup
- [ ] Integration test: Socket file is removed on graceful shutdown

## Out of Scope

- IPC protocol parsing (E003 - IPC Protocol & Client)
- Session store operations (S001.03)
- Broadcasting updates to subscribers (part of IPC Protocol)
- Message processing logic (handled by event loop in separate stories)

## Notes

### Socket Architecture

```text
┌─────────┐     ┌─────────┐     ┌─────────┐
│  Hook   │     │  Hook   │     │   TUI   │
│ Client  │     │ Client  │     │ Client  │
└────┬────┘     └────┬────┘     └────┬────┘
     │               │               │
     └───────────────┼───────────────┘
                     │
                     ▼
          ┌─────────────────────┐
          │   UnixListener      │
          │   (tokio async)     │
          ├─────────────────────┤
          │ /tmp/agent-console  │
          │        .sock        │
          └─────────────────────┘
```

### Event Loop Integration

```rust
loop {
    tokio::select! {
        conn = listener.accept() => handle_new_connection(conn, tx.clone()),
        Some(msg) = rx.recv() => process_message(msg, &mut state),
        _ = usage_interval.tick() => fetch_usage_if_subscribers(),
        _ = auto_stop_interval.tick() => check_auto_stop(),
    }
}
```

Connections are accepted, then each connection task sends messages to the `tx`
(mpsc sender). The single `rx` (mpsc receiver) processes messages sequentially.

### Error Handling

- Address in use: Remove stale socket and retry (per D6)
- Permission denied: Log clear error about path permissions
- Connection reset: Clean up client state silently

### Performance Targets

| Metric                 | Target |
| ---------------------- | ------ |
| Connection accept time | <1ms   |
| Message read/write     | <1ms   |
| Max concurrent clients | 100+   |

### Socket Cleanup Strategy

Per [D6](../architecture/2026-01-31-discussion-decisions.md): Remove socket file
on daemon shutdown (auto-stop, SIGTERM, `acd stop`). With 60-minute auto-stop
timeout and auto-start capability, stale sockets should not occur under normal
operation.
